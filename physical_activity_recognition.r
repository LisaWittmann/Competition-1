{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"font-size:24px; \n            text-align:center;\n            border-radius: 0px 0px 50px 50px;\n            background: #581C3D;\n            color: #F3F3F3;\n            padding: 10px;\">\n    <b>\n        Physical Activity Recognition - BDA Competition 2023\n    </b>\n    <br>        \n    <span style='font-size:18px;'>\n        Round 2, Group 12: Eeva Hökkä, Lisa Wittmann, Lutz Heil\n    </span>\n</div>\n","metadata":{"_uuid":"93de3694eaabf3b22b62e4876069a9cf8f92fb7e","_execution_state":"idle","execution":{"iopub.status.busy":"2023-09-24T20:01:35.718827Z","iopub.execute_input":"2023-09-24T20:01:35.721477Z","iopub.status.idle":"2023-09-24T20:01:39.536549Z"}}},{"cell_type":"markdown","source":"# Introduction\nThis competition involves building a classifier that recognizes different types of physical activity from signals measured by the accelerometer and gyroscope in your smartphone, which both measure aspects of movement and orientation. The data for this competition were collected in a lab using a basic smartphone in experiments with human participants carrying out various daily activities in set order.   \nFor more details on the data collection consult the [Kaggle competition site](https://www.kaggle.com/competitions/physical-activity-recognition-bda-2023/overview).\n\n## Overview to this notebook\n\n[1️⃣ Setup](#setup)   \n[2️⃣ Data import \\& pre-processing](#data_import)   \n[3️⃣ Feature creation](#feature_creation)   \n[4️⃣ Training data feature extraction](#training_data)   \n[5️⃣ Model fitting](#model_fitting)   \n[6️⃣ Prediction on test data](#predcition_test)   \n[7️⃣ Formatting the submission file](#submission)   \n[8️⃣ References \\& Declaration of work](#refs_decl)   \n\n</br>\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"<h1 id = setup style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    1. Setup\n</h1>\n\nWe start off load the required packages form the `tidyverse` group and `caret`.<br>Next, we copy all required files to our working directory.","metadata":{}},{"cell_type":"code","source":"# Packages\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(caret))\nsuppressPackageStartupMessages(require(gridExtra))\n\n# Copy all files to the working directory\nsystem(paste0(\"cp -r \", list.files(\"../input\", pattern = \"recognition\", full.names=TRUE), \"/* ./\"))\n","metadata":{"_uuid":"93de3694eaabf3b22b62e4876069a9cf8f92fb7e","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id = data_import style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px;  border-radius: 10px;'>\n    2. Data import & pre-processing\n</h1>\n\nWe begin by reading in the activity labels and attaching them to the correct samples in the training data.<br>(*Note: The code in this section has been given in the quickstart notebook*).\n\n## 2.1 Importing activity labels\n\nWe first retrieve the 12 activity labels, then load the training data labels and finally attach the activity labels to the respective training data. These are the activity labels that we are attempting to predict on the test data. Hence they represent our categorical response variable.","metadata":{}},{"cell_type":"code","source":"# read in activity label\nact_labels <- read_delim(\"activity_labels.txt\", \" \",\n  col_names = FALSE,\n  trim_ws = TRUE,\n  show_col_types = FALSE\n)\nact_labels <- act_labels %>% select(X1, X2)\nhead(act_labels)\n\n# load in labels for training data\nlabels <- read_delim(\"./RawData/Train/labels_train.txt\",\n  \" \",\n  col_names = FALSE,\n  show_col_types = FALSE\n)\ncolnames(labels) <- c(\"trial\", \"userid\", \"activity\", \"start\", \"end\")\n\n# replace label for word label\nlabels <- labels %>% mutate(activity = act_labels$X2[activity])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Generate sample id\n\nInstead of the variables `start` and `end`, we generate a sample id. The sample id represents the time point at which the signal data has been measured.","metadata":{}},{"cell_type":"code","source":"# Add the sequence start:end to each row in a list.\n# The result is a nested table:\nsample_labels_nested <-\n  labels %>%\n  rowwise() %>% # do next operation(s) rowwise\n  mutate(sampleid = list(start:end)) %>%\n  ungroup()\n\n# Unnest the nested tabel.\nsample_labels <-\n  sample_labels_nested %>%\n  # Rows are segments, we need to keep track of different segements\n  mutate(segment = row_number()) %>%\n  # Expand the data frame to one sample per row\n  unnest(cols = c(sampleid)) %>%\n  # Remove columns we don't need anymore\n  select(-start, -end)\n\n# check labels\nhead(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Input Data Description\n\nAlthough loading the signal input data will be done in section 4 we shortly describe the structure of the input data:\n\nThe datafiles we are importing from the accelerometer and gyroscope come in three variables each. The accelerometer variables record movement in three planes - up and down, front and back, and sideways. The gyroscope variables record the orientation of the device - tilt along the long sides, tilt along the short sides, and rotation.","metadata":{}},{"cell_type":"markdown","source":"<h1 id = feature_creation style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    3. Feature Creation\n    </h1>\n\nIn this section, we are only creating feature functions that we will use in section 3. In section 3 we will create a function that imports a single signal file and extracts our selected features using the feature functions that we will build in this section.\n\nOur feature functions can be categorized into different groups:\n* Statistical features\n* Histogram features\n* Time domain features\n* Frequency domain features\n\n## 3.1 Statistical Features\n\nSimple descriptive measures can give valuable insights in the signal processing. Here we can draw some parallels: \n\n* **power** = Summed of squared means plus the variance. It can be interpreted as the \"loudness\" of a signal of an entire set of samples.\n* **energy** = Displays the total power of all samples by simply multiplying power and sample size.","metadata":{"_uuid":"903d9aabb30f663db30ee64963d4165f6ad8a14f"}},{"cell_type":"code","source":"# Power\npower <- function(x) {\n  power <- mean(x^2)\n  return(power)\n}\n\n# Energy\nenergy <- function(x) {\n  energy <- sum(x^2)\n  return(energy)\n}\n","metadata":{"_uuid":"6cec2d0fa3e99e2d924c24ac55c5d462ae666707","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Histogram Features\n\nIn this section, we create features, that rely on a variety of distributional properties of the signal variables in each epoch.\n\n*The following features belong in this section but are not created here since functions already exist:*\n* **Mean**: The average absolute value of a signal across samples in a time window.\n* **Standard Deviation**: This is the mean distance between the signal data points and their mean.\n* **Variance**: The variance is also a measure of power.\n* **Skew**:Measure of asymmetry in the signals' distribution.\n* **Kurtosis**: Measure of the relative peak property of the signals' distribution.\n* **Quantiles**: 25% and 75% quantiles measuring the distribution boundary of 25% or 75% of the signal\n* **Interquartile Range**: The range between the 25th and 75th percentiles, thereby measuring the spread of the signal data in the middle 50%.\n* **Number of values below mean**: **Source: Group 15**\n\n*The following feature functions are created in the following subsections.*\n* **Mode**: The most frequently occuring value of a signal. Here we also calculated if there are multiple modes, i.e. a multimodal distribution.\n* **Entropy**: Measure of the unpredictability or ‘surprise’ of a signal.\n* **Differences of Means**: Measure of the distance between two signals (i.e. two variables).\n* **Integration**: Measure of the size of the signal's histogram using a density function.\n* **Area Overlap**: Measure of the size of the overlapping distributions of two signals.\n* **Root Mean Square**: Measure of the amplitude of a signal.","metadata":{}},{"cell_type":"markdown","source":"### 3.2.1 Mode features\n\nThe mode is a difficult feature since data can yield multiple modes. How do we choose which mode we want to use? We created functions to detect the number of modes as well as the one mode or multiple modes\nThese functions stored and tested within the R-file \"find-mode.R\".\n\n* `n_modes` = Number of modes\n* `find_mode1` = Finds the first (or only) mode in the data\n* `find_mode2` = Finds the second mode in the data. If there is only one mode, it will return this mode.\n* `find_mode3` = Finds the third mode in the data. If there are only two modes, it will return the second mode, which in turn will be the first mode in the case of only one mode.\n\nWe could implement even more, but more than three modes don't seem necessary or valuable. Probably the second and third mode will even be unneccessary.\n\n**Quoate from Group: Sensors_02**\n\nThe median absolute deviation (MAD) is part of the measures for the spread of the data. We chose to include MAD based on the 2017 study by Zhu et al., which like us created a model that recognizes the type of physical activity based on signals, including accelerometer and gyroscope signals. MAD is a measure of distance from the median, and is thereby more robust against outliers.","metadata":{}},{"cell_type":"code","source":"# Defining the find_mode function\nfind_mode <- function(x) {\n  u <- unique(x)\n  tab <- tabulate(match(x, u))\n  return(u[tab == max(tab)])\n}\n\n# get the number of modes\nn_modes <- function(x) {\n  return(length(find_mode(x)))\n}\n\n# find first mode\nfind_mode1 <- function(x) {\n  return(find_mode(x)[1])\n}\n\n# find second mode\nfind_mode2 <- function(x) {\n  if (n_modes(x) > 1) {\n    return(find_mode(x)[2])\n  } else {\n    return(find_mode1(x))\n  }\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.2 Entropy\nEntropy is the average surprise or randomness in a signal. ","metadata":{}},{"cell_type":"code","source":"entro <- function(x, nbreaks = nclass.Sturges(x)) {\n  r <- range(x)\n  x_bin <- findInterval(x, seq(r[1], r[2], len = nbreaks))\n  h <- tabulate(x_bin, nbins = nbreaks)\n  p <- h / sum(h)\n  entropy <- -sum(p[p > 0] * log(p[p > 0]))\n  return(entropy)\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.3 Differences of means\nBy the visual inspection of the histograms of different users, we thought that it is important to catch the relation of how X1, X2 and X3 stand to each other. As one reoccuring pattern we identified the arrangement of the three histograms for one specific movement, which can be displayed in the relative mean difference to each other. ","metadata":{}},{"cell_type":"code","source":"# Differences between means of X1/2/3\nmean_diffs <- function(x, y) {\n  Diffs <- mean(x) - mean(y)\n  return(Diffs)\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.4 Integration - calculated area of histogram\nAnother result of our visual inspection of the histograms was that the histograms of the different users for the movement were on top of each other. So we really wanted to have area as a feature, as it also captures many other features of the histogram, such as height, which varies greatly from movement to movement.\nInstead of calculating literally the area under the histograms using their midpoints and height etc., we chose the build-in density function, which facilitated us to integrate, in order to get the total area under the curve (or visually the area of the histogram). Only adding the area of one variable as a features is not reasonable, as it would not differ a lot, that why we focused on our next step on the relative overlap of the variables.\n    \n","metadata":{}},{"cell_type":"markdown","source":"### 3.2.5 Area overlap\nSimilar to the differences of mean, we wanted to include another relative measurement, which should help in the end with pattern detection between X1, X2, and X3. By looking at the multiple histograms, we thought the area overlapping could also be a good indication of that.","metadata":{}},{"cell_type":"code","source":"# Area overlap\narea_overlap <- function(x, y) {\n  df <- data.frame(x = x,\n                   y = y)\n  # compute density values for both variables\n  x_dens <- density(df$x,\n                     from = min(df),\n                     to = max(df))\n  y_dens <- density(df$y,\n                     from = min(df),\n                     to = max(df))\n  # using pmin on the y-values of the density functions\n  # returns the y-values for the overlap density function\n  joint_dens <- pmin(x_dens$y, y_dens$y)\n  # finally using a trapez function to calculate the integrale of the\n  # overlapping area. This approach matches exactly the approximation for \n  # integrating the function using the trapezoidal rule with basepoints x.\n  auc_overlap <- pracma::trapz(x_dens$x, joint_dens)\n  return(auc_overlap)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.6 Root Mean Square (RMS)\nThis is a measure of the amplitude of the signal. The histograms suggested varying RMS measures for the different ability measures. Thus, we include this feature.","metadata":{}},{"cell_type":"code","source":"# Root Mean Square (RMS) \nrms <- function(x) {\n    mean_squares = mean(x^2)\n    rms_val = sqrt(mean_squares)\n    return(rms_val)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.7 MAD - Median Absolute Deviation (credit go to Group 02)¶\n\n>The median absolute deviation (MAD) is part of the measures for the spread of the data. We chose to include MAD based on the 2017 study by Zhu et al., which like us created a model that recognizes the type of physical activity based on signals, including accelerometer and gyroscope signals. MAD is a measure of distance from the median, and is thereby more robust against outliers. *Quote from Group: Sensors_02*\n\nWe were convinced by the literature-based reasoning to adopt the MAD as a new feature. Given the sometimes very noisy signal in the data, it also seems reasonable to implement a feature that is more robust against outliers.","metadata":{}},{"cell_type":"code","source":"# The functions below is quoted from Group 2\n# Median absolute deviation (MAD)\nMAD <- function(x) {\n\n# Calculate the median of the signal\n  median <- median(x)\n\n# Calculate the absolute differences between each data point and the median\n  abs_diff <- abs(x - median)\n  \n# Calculate the MAD by taking the median of the absolute differences\n  mad <- median(abs_diff)\n  \n  return(mad)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Time Domain Features\nWhereas the previous mentioned descriptive statistics ignore the time domain of feature, we focus here on some measures that try to catch the order of events. \n\n*The following feature functions are created in this section:*\n* **Cosine Angle**: Similarity of two signals for a given timepoint.\n* **Autocorrelation / Lagged correlation**: Measure of the similarity between a signal and the same signal at a different time point (lag = how many time points have been shifted).\n* **Lagged cross-correlation**: Measure of the similarity between two signals with one of which being lagged.\n\n### 3.3.1 Cosine Angle\nOne way to deal with order is to calculate the cosine angle, which shows how similar two variables for a given timepoint are. This is based on correlation, but using the scaled inner product works as well. ","metadata":{}},{"cell_type":"code","source":"# Cosine angle: scaled inner product of 2 variables\ncosine_angle <- function(x, y) {\n  cos_ang <- x %*% y / sqrt(sum(x^2) * sum(y^2))\n  return(cos_ang)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.2 Lagged correlation\nAnother way to take the order into account is computing the auto-correlation between one sample and the one before (called immediate lag). This step back can be seen as a step back in time. We varied this step also by two and three steps back in time to catch bigger time frames. Thus, lags used = 1, 2, 3.\n\nWe can also compare how similar two different variables are at different timepoints, through lagged cross-correlation. For example, we can compare the similarity between X1 at this timepoint, and X3 at 1 or 2 timepoints (sample_ids) behind, to see if the two variables are just time-shifted versions of each other.\n\nOne **problem**, we came across using lagged correlation is that we produced NAs, when we wanted to predict e.g. AR1_3acc for user04, trial 7 or AR1_4_acc for user09, trial 18. We found out that these two users have not enough samples in certain epochs (138 and 122; 4 and 5 samples respectively) to compute lagged correlation with a lag greater than 2 or 3. Our first approach was to elimanate those two epochs form the prediction, i.e. setting their activiy label to NA. However, that would mean our test data prediction accuray would always be limited even though our model might have been able to predict the activity label well by using other predictors. As a result, we decided to set the lagged correlations two 0 if they were to return NAs. That way, we might not have a correct predictor value, but our model would be able to predict activity labels.","metadata":{}},{"cell_type":"code","source":"lagged_cor_1 <- function(x, y = x, lag = 1) {\n  # compute correlation between x and a time shifted y\n  r_lagged <- cor(x, dplyr::lag(y, lag), use = \"pairwise\")\n  if (is.na(r_lagged)) {\n    r_lagged <- 0\n  }\n    return(r_lagged)\n}\n\nlagged_cor_2 <- function(x, y = x, lag = 2) {\n  # compute correlation between x and a time shifted y\n  r_lagged <- cor(x, dplyr::lag(y, lag), use = \"pairwise\")\n  if (is.na(r_lagged)) {\n    r_lagged <- 0\n  }\n    return(r_lagged)\n}\n\nlagged_cor_3 <- function(x, y = x, lag = 3) {\n  # compute correlation between x and a time shifted y\n  r_lagged <- cor(x, dplyr::lag(y, lag), use = \"pairwise\")\n  if (is.na(r_lagged)) {\n    r_lagged <- 0\n  }\n    return(r_lagged)\n}\n\nlagged_cor_4 <- function(x, lag = 4) {\n  # compute correlation between x and a time shifted y\n  r_lagged <- cor(x, dplyr::lag(x, lag), use = \"pairwise\")\n  if (is.na(r_lagged)) {\n    r_lagged <- 0\n  }\n    return(r_lagged)\n}\n\n# For the lagged cross-correlation (between two different variables, e.g. X1 and X2),\n# we can just specify y.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Frequency domain features\n\nFrequency domain features (also known as \"spectral\" features) are described in the reading materials ([Feature extraction from Signals](https://paper.dropbox.com/doc/Feature-extraction-from-Signals--A62tmtXDMS34X292NP0fKphQAQ-qCp5uvj47gmyuw5nmB8lL)).\n\n\nThe following feature functions are created in this section:\n- `peak_freq_loc`: The location of the peak frequency among the spectral bands\n- `entr_spec`: The spectral entropy of frequency bands within an epoch\n- `mean_spec`: The mean of the spectrum\n- `sd_spec`: The standard deviation of the spectrum\n\nThe functions below are from **source: Group1**\n- `spec_mode`: The mode of the spectrum\n- `spec_kurt`: The kurtosis of the spectrum\n- `spec_median`: The median of the spectrum\n- `spectral_energy`: The spectral energy of the frequency bands within an epoch\n\nThe function below is from **source: Group5**\n- `max_spectral_mag_lin`: Frequency of maximum magnitude of spectrum","metadata":{}},{"cell_type":"code","source":"# Location of peak, smoothed\npeak_freq_loc <- function(x) {\n  spectrum <- spectrum(x, plot = FALSE)\n  peak_freq_loc <- spectrum$freq[which.max(spectrum$spec)]\n  return(peak_freq_loc)\n}\n\n# Spectral entropy (see Grasman, 2018)\nentr_spec <- function(x) {\n  spec <- spectrum(x, plot = FALSE)$spec\n  entro(spec)\n}\n\n# Spectral mean (see Grasman, 2018)\nmean_spec <- function(x) {\n  spec <- spectrum(x, plot = F)\n  df <- spec$freq[2] - spec$freq[1]\n  return(sum(spec$freq * spec$spec * df))\n}\n\n# Spectral SD (see Grasman, 2018))\nsd_spec <- function(x) {\n  spec <- spectrum(x, log = \"n\", plot = FALSE)$spec\n  freq <- spectrum(x, log = \"n\", plot = FALSE)$freq\n  df <- freq[2] - freq[1]\n\n  return(sqrt(sum((freq - mean(x))^2 * spec * df)))\n}\n\n# Spectral mode (source: Group 16)\nspec_mode <- function(x) {\n  spec_features <- spectrum(x, plot = FALSE)\n  mode <- max(spec_features$spec)\n  return(mode)\n}\n\n# Spectral kurtosis (source: Group 16)\nspec_kurt <- function(x) {\n  spec_features <- spectrum(x, plot = FALSE)\n  kurt <- e1071::kurtosis(spec_features$spec)\n  return(kurt)\n}\n\n# Spectral median (source: Group 16)\nspec_median <- function(x) {\n  spec_features <- spectrum(x, plot = FALSE)\n  median <- median(spec_features$spec)\n  return(median)\n}\n\n# Spectral energy (source: Group 1)\nspectral_energy <- function(x) {\n  spec <- spectrum(x, plot = FALSE)\n  energy <- sum(spec$spec)\n  return(energy)\n}\n\n# Maximum spectral magnitude (source: Group 5)\nmax_spectral_mag_lin <- function(x, s) {\n  if (length(x) < s) {\n    return(0)\n  }\n  spec <- spectrum(x, log = \"n\", span = s, plot = FALSE)\n  return(spec$freq[which.max(spec$spec)])\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Additional features from other groups\n\nAfter studying the other groups' notebooks in round 1, we selected a few features that were underpinned by good reasoning and implemented them here. Remarkably, Group 13 even consulted further literature. Chapeau!\n\n**Source: Group 13**\n- `Signal Magnitude Area (SMA)`: SMA is a commonly used feature in dealing with accelerometer data. Calculated as the sum of absolute values of the three axis averaged over a window, it tells us about the intensity of a signal in a particular context and time (Carus et al., 2012).\n- `Average Resultant Acceleration (ARA)`: ARA is another popular feature of motion recognition. Similarly to SMA, it allows to assess the magnitude of motion in a specific timeframe, as well as acceleration over a specific time. It is calculated by taking the average of the square roots of the values in each of the three axis squared and added together (Mero, 2013).\n- `Distance Between Peaks`: Unlike other features that focus on assessing the magnitude of motion or acceleration, Distance Between Peaks delves into the temporal aspects of motion data. It involves the calculation of time intervals between consecutive peak points in the sensor data within an epoch, offering unique insights into movement patterns and transitions.\n- `Zero Crossing Rate`: The Zero-Crossing Rate (ZCR) of an audio frame is the rate of sign-changes of the signal during the frame. In other words, it is the number of times the signal changes value, from positive to negative and vice versa, divided by the length of the frame. (Giannakopoulos & Pikrakis, 2014).\n\n**Source: Group 1**\n- `slope`: Fitting linear regression to all data points within an epoch (X~sampleid) and extracting the slope.\n- `absolute movement`: The absolute movement for one or mutliple axes.","metadata":{}},{"cell_type":"code","source":"# Source: Group 13\n# Signal Magnitude Area\nsma <- function(x1, x2, x3) {\n  m1 <- mean(x1)\n  m2 <- mean(x2)\n  m3 <- mean(x3)\n  sma_values <- rowSums(abs(data.frame(m1, m2, m3)) / 100)\n  return(sma_values)\n}\n\n# Average Resultant Acceleration\nara <- function(x1, x2, x3) {\n  sqrt_sum_squares <- sqrt(x1^2 + x2^2 + x3^2) # rsm for each time point\n  avg_resultant_acceleration <- mean(sqrt_sum_squares) # average\n  return(avg_resultant_acceleration)\n}\n\n# Distance between Peaks\ndistance_max <- function(signal) {\n  indices <- order(signal, decreasing = TRUE)\n  index1 <- indices[1]\n  index2 <- indices[2]\n  distance <- abs(index2 - index1)\n  return(distance)\n}\n\n# Zero Crossing Rate\ncalculate_ZCR <- function(signal) {\n  zero_crossings <- 0\n  for (i in 2:length(signal)) {\n    if (sign(signal[i]) != sign(signal[i - 1])) {\n      zero_crossings <- zero_crossings + 1\n    }\n  }\n\n  zcr <- zero_crossings / (length(signal) - 1)\n\n  return(zcr)\n}\n\n# Source: Group 1\nabsolute_movement <- function(vectors) {\n  return(sum(abs(vectors)))\n}\n\nslope <- function(x) {\n  return(lm(x ~ seq_along(x))$coefficients[2])\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id = training_data style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    4. Training data feature extraction\n</h1>\n\nNow, we have defined our features and written functions that can extract those features from the input data. The next step is to load the training data and apply those functions in order to obtain a training data set that contains our feature variables. \n\nTo get there, we first build a given function `extract_features` which loads a single file, extracts the features and merges everything in a dataframe.   \nNext, we apply that function \n\na) to all files for the **accelerometer** data and join them in on dataframe called `my_data_acc`   \nb) to all files for the **gyroscope** data and join them in on dataframe called `my_data_gyr`.\n\nFinally we merge these two data frames into one training data set called `my_data`.\n\n","metadata":{"_uuid":"70f82939d0025cd90b72ea9b46b23c9a110f4f38"}},{"cell_type":"markdown","source":"## 4.1 Define `extract_features` - function","metadata":{}},{"cell_type":"code","source":"# helper function\nmost_common_value <- function(x) {\n  counts <- table(x, useNA = \"no\")\n  most_frequent <- which.max(counts)\n  return(names(most_frequent))\n}\n\nextract_features <- function(filename, sample_labels) {\n  # extract user and experimental run ID's from file name\n  username <- gsub(\".+user(\\\\d+).+\", \"\\\\1\", filename) %>% as.numeric()\n  expname <- gsub(\".+exp(\\\\d+).+\", \"\\\\1\", filename) %>% as.numeric()\n\n  # import the sensor signals from the file\n  user01 <- read_delim(filename, \" \",\n    col_names = F, progress = TRUE,\n    col_types = \"ddd\"\n  )\n\n  # merge signals with labels\n  user_df <-\n    data.frame(userid = username, trial = expname, user01) %>%\n    mutate(sampleid = 0:(nrow(user01) - 1)) %>%\n    left_join(sample_labels, by = c(\"userid\", \"trial\", \"sampleid\"))\n\n\n  # split in epochs of 128 samples and compute features per epoch\n  usertimedom <- user_df %>%\n    # add an epoch ID variable (on epoch = 2.56 sec)\n    mutate(epoch = sampleid %/% 128) %>%\n    # extract statistical features from each epoch\n    group_by(epoch) %>%\n    summarise(\n      # keep track of user and experiment information\n      user_id = username,\n      exp_id = expname,\n\n      # epoch's activity labels and start sample\n      activity = most_common_value(c(\"-\", activity)),\n      sampleid = sampleid[1],\n\n      # SIGNAL FEATURES\n\n      # Mean & SD\n      m1 = mean(X1),\n      m2 = mean(X2),\n      m3 = mean(X3),\n      sd1 = sd(X1),\n      sd2 = sd(X2),\n      sd3 = sd(X3),\n\n      # Ranges\n      min1 = min(X1),\n      min2 = min(X2),\n      min3 = min(X3),\n      max1 = max(X1),\n      max2 = max(X2),\n      max3 = max(X3),\n      range1 = max1 - min1,\n      range2 = max2 - min2,\n      range3 = max3 - min3,\n      q1_25 = quantile(X1, .25),\n      q1_75 = quantile(X1, .75),\n      q2_25 = quantile(X2, .25),\n      q2_75 = quantile(X3, .75),\n      q3_25 = quantile(X3, .25),\n      q3_75 = quantile(X3, .75),\n      q_range1 = q1_75 - q1_25,\n      q_range2 = q2_75 - q2_25,\n      q_range3 = q3_75 - q3_25,\n      iq_range1 = (q1_75 + sd1) - (q1_25 - sd1),\n      iq_range2 = (q2_75 + sd2) - (q2_25 - sd2),\n      iq_range3 = (q3_75 + sd3) - (q3_25 - sd3),\n      high_whisker1 = q1_75 + sd1,\n      high_whisker2 = q2_75 + sd2,\n      high_whisker3 = q3_75 + sd3,\n      low_whisker1 = q1_25 - sd1,\n      low_whisker2 = q2_25 - sd2,\n      low_whisker3 = q3_25 - sd3,\n      rms1 = rms(X1),\n      rms2 = rms(X2),\n      rms3 = rms(X3),\n\n      # Median & Mode\n      median1 = median(X1),\n      median2 = median(X2),\n      median3 = median(X3),\n      mode1 = find_mode1(X1),\n      mode2 = find_mode1(X2),\n      mode3 = find_mode1(X3),\n      bimodal1 = find_mode1(X1) == find_mode2(X1),\n      bimodal2 = find_mode1(X2) == find_mode2(X2),\n      bimodal3 = find_mode1(X3) == find_mode2(X3),\n      mad1 = MAD(X1),  # source:  Group 2 \n      mad2 = MAD(X2),\n      mad3 = MAD(X3),\n      nVBM_1 = sum(X1 < mean(X1)), # source: Group 15\n      nVBM_2 = sum(X2 < mean(X2)),\n      nVBM_3 = sum(X3 < mean(X3)),  \n        \n      # Distribution shapes\n      skew1 = e1071::skewness(X1),\n      skew2 = e1071::skewness(X2),\n      skew3 = e1071::skewness(X3),\n      kurt1 = e1071::kurtosis(X1),\n      kurt2 = e1071::kurtosis(X2),\n      kurt3 = e1071::kurtosis(X3),\n\n      # Lagged correlations\n      AR1_1 = lagged_cor_1(X1),\n      AR1_2 = lagged_cor_2(X1),\n      AR1_3 = lagged_cor_3(X1),\n      AR1_4 = lagged_cor_4(X1),\n      AR2_1 = lagged_cor_1(X2),\n      AR2_2 = lagged_cor_2(X2),\n      AR2_3 = lagged_cor_3(X2),\n      AR2_4 = lagged_cor_4(X2),\n      AR3_1 = lagged_cor_1(X3),\n      AR3_2 = lagged_cor_2(X3),\n      AR3_3 = lagged_cor_3(X3),\n      AR3_4 = lagged_cor_4(X3),\n      AR12_1 = lagged_cor_1(X1, X2),\n      AR12_2 = lagged_cor_2(X1, X2),\n      AR13_1 = lagged_cor_1(X1, X3),\n      AR13_2 = lagged_cor_2(X1, X3),\n      AR23_1 = lagged_cor_1(X2, X3),\n      AR23_2 = lagged_cor_2(X2, X3),\n\n      # Our own features\n      mean_diff_1_2 = mean_diffs(X1, X2),\n      mean_diff_1_3 = mean_diffs(X1, X3),\n      mean_diff_2_1 = mean_diffs(X2, X1),\n      mean_diff_2_3 = mean_diffs(X2, X3),\n      mean_diff_3_1 = mean_diffs(X3, X1),\n      mean_diff_3_2 = mean_diffs(X3, X2),\n      area_under_curve_1_2 = area_overlap(X1, X2),\n      area_under_curve_1_3 = area_overlap(X1, X3),\n      area_under_curve_2_3 = area_overlap(X2, X3),\n      pow1 = power(X1),\n      pow2 = power(X2),\n      pow3 = power(X3),\n      energy1 = energy(X1),\n      energy2 = energy(X2),\n      energy3 = energy(X3),\n      entropy1 = entro(X1),\n      entropy2 = entro(X2),\n      entropy3 = entro(X3),\n      cos_ang1 = cosine_angle(X1, X2),\n      cos_ang2 = cosine_angle(X1, X3),\n      cos_ang3 = cosine_angle(X2, X3),\n      peak_freq_loc1 = peak_freq_loc(X1),\n      peak_freq_loc2 = peak_freq_loc(X2),\n      peak_freq_loc3 = peak_freq_loc(X3),\n      mean_spec1 = mean_spec(X1),\n      mean_spec2 = mean_spec(X2),\n      mean_spec3 = mean_spec(X3),\n      sd_spec1 = sd_spec(X1),\n      sd_spec2 = sd_spec(X2),\n      sd_spec3 = sd_spec(X3),\n      spec_mode1 = spec_mode(X1),  # source: Group 16 \n      spec_mode2 = spec_mode(X2), \n      spec_mode3 = spec_mode(X3), \n      spec_kurt1 = spec_kurt(X1),  # source: Group 16 \n      spec_kurt2 = spec_kurt(X2),  \n      spec_kurt3 = spec_kurt(X3),\n      spec_median1 = spec_median(X1), # source: Group 16 \n      spec_median2 = spec_median(X2),\n      spec_median3 = spec_median(X3),\n      spec_energy1 = spectral_energy(X1), # source: Group 1 \n      spec_energy2 = spectral_energy(X2),\n      spec_energy3 = spectral_energy(X3),\n      maxmag_x1_11_lin = max_spectral_mag_lin(X1, 11), # source: Group 5\n      maxmag_x2_11_lin = max_spectral_mag_lin(X2, 11),\n      maxmag_x3_11_lin = max_spectral_mag_lin(X3, 11),\n        \n      # special features from literature\n      zcr_x1 = calculate_ZCR(X1), # source: Group 13\n      zcr_x2 = calculate_ZCR(X2),\n      zcr_x3 = calculate_ZCR(X3),\n      dist_max_x1 = distance_max(X1), # source: Group 13\n      dist_max_x2 = distance_max(X2),\n      dist_max_x3 = distance_max(X3),\n      sma = sma(X1,X2,X3), # source: Group 13\n      ara = ara(X1,X2,X3), # source: Group 13\n      slope_x1 = slope(X1), # source: Group 1\n      slope_x2 = slope(X2),\n      slope_x3 = slope(X3),\n      abs1 = absolute_movement(X1), # source: Group 1 \n      abs2 = absolute_movement(X2),\n      abs3 = absolute_movement(X3),\n        \n      # keep track of signal lengths\n      n_samples = n()\n    )\n\n  usertimedom\n}","metadata":{"_uuid":"daccc2b4175580864f72a2012ef6d56ee7c0a883","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Apply function to all accelerometer files\n\nUsing regex, we identify our accelerometer files and apply our `extract_features` function for data import and file extraction to each one of them. Using the `map_df` function, we combine the resulting datasets for all the files and attach the sample_labels.","metadata":{}},{"cell_type":"code","source":"# get filenames\nfilenames <- dir(\"./RawData/Train/\", \"^acc\", full.names = TRUE)\n\n# map_dfr runs `extract_features` on all elements in\n# filenames and binds results row wise\nacc_df <- map_dfr(filenames, extract_features, sample_labels)\n\n# check the result\nhead(acc_df)\n","metadata":{"_uuid":"c2572d092b5b590a3f6dcc67313ff5f690beb471","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Apply function to all gyroscope files\n\nNow, we do so in analogous manner for the gyroscope files.","metadata":{}},{"cell_type":"code","source":"# get filenames for gyroscope data\nfilenames <- dir(\"./RawData/Train/\", \"^gyr\", full.names = TRUE)\n\n# map_dfr runs `extract_features` on all elements in\n# filenames and binds results row wise\ngyr_df <- map_dfr(filenames, extract_features, sample_labels)\n\n# check the result\nhead(gyr_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4. Merge accelerometer and gyroscope training data\n\nFinally, we join the datasets from the two different signal sources together in order to obtain our joined training data set with all extracted features and the respective responses (activity labels).","metadata":{}},{"cell_type":"code","source":"train_df <- acc_df %>%\n  left_join(gyr_df,\n    by = c(\"epoch\", \"user_id\", \"exp_id\", \"activity\", \"sampleid\", \"n_samples\"),\n    suffix = c(\"_acc\", \"_gyr\")\n  )\nhead(train_df)\ndim(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.5 Cleaning training data\nWhen checking our training data,we can observe two phenomena that might be problemativ for the subsequent predictive goals of this competition:\n* 1352 samples are labeled as \"-\" instead of a certain activity\n* not all epochs contain the full amount of 128 samples\n","metadata":{}},{"cell_type":"code","source":"table(train_df$activity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table(train_df$n_samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll exclude these cases from the training data set, since low sample id count and no activity labels are not useful for training the classifier.","metadata":{}},{"cell_type":"code","source":"train_df_clean <- train_df %>%\n  filter(\n    activity != \"-\",\n    n_samples == 128\n  )\n\nhead(train_df_clean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id = model_fitting style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    5. Model fitting\n</h1>\n\nBefore we start fitting models, we check for variables that might unneccessarily obstruct our models because of variance close to zero, highly correlated variables, or multicollinear combinations of variables.\n \n\n## 5.1 Check near zero variance, highly correlations, and multicollinearity\n\nAs our next step was to check our features on NearZeroVariance, high correlation and multicollinearity. Our results were, that there was no variables with near zero variance, but we detected variables with correlation higher than 0.8 and also observed multicollinarity. In this case we excluded these features from our cleaned training data.    \nNotably, we chose a **lower cutoff** (.8 instead of .9) for highly correlated variables. This change was implemented in order to reduce the number of predictors beacuse in round 1 of the competition, we were certainly overfitting (training data accuracy = .89 vs. test data accuracy = .68). ","metadata":{"_uuid":"689e96162446707ee9e88a4c229d169f76290b62"}},{"cell_type":"code","source":"train_preds <- train_df_clean %>%\n  select(-c(\"epoch\", \"user_id\", \"exp_id\", \"activity\", \"sampleid\", \"n_samples\"))\n\nn_non_preds <- ncol(train_df_clean) - ncol(train_preds)\n\n# Check for NearZero Variance\nrm_near_zero <- caret::nearZeroVar(train_preds)\n\n# Check for highly correlated variables\ncor_mat <- cor(train_preds)\nrm_highly_cor <- caret::findCorrelation(cor_mat, cutoff = .8)\n\n# Check for multicolloinearity\nrm_multicol <- caret::findLinearCombos(train_preds)$remove\n\n\n# Remove variables from myData_clean dataset\nrm_indices <- c(rm_near_zero, rm_highly_cor, rm_multicol) %>% unique()\nrm_indices <- names(train_preds[rm_indices])\n\ntrain_df_clean <- train_df_clean %>% select(-all_of(rm_indices))\ncat(\n  \"Number of predictors before removal:\", ncol(train_preds), \"\\n\\n\",\n  \"Cleaned data set after predictor removal:\\n\\nNumber of variables in the data set: \",\n  ncol(train_df_clean), \"\\n\",\n  \"Number of non-predictor variables: \", n_non_preds, \"\\n\",\n  \"Number of predictors: \", ncol(train_df_clean) - n_non_preds\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, remove all non-predictor variables that are not response variables in order to get a data frame that is useful for model fitting purposes.","metadata":{}},{"cell_type":"code","source":"train_df_clean <- train_df_clean %>% \n    select(-c(\"epoch\", \"user_id\", \"exp_id\", \"sampleid\", \"n_samples\")) \nhead(train_df_clean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Classification with different algorithms\n\nFor cross-validation, k = 5 folds should be a good middle ground between LOOCV and k = 10 folds due to the otherwise existing bias-variance trade-off as described in Chap. 5 (ISLR).\n\n\n\n### 5.2.1 Defining 5-fold cross validation","metadata":{}},{"cell_type":"code","source":"# Defining 5-fold cross validation (for all models)\ntrcntr <- trainControl('cv', number = 5, p = 0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Interim conclusion - after first round of submission:* \n\n*As we noted in our first round of submissions, our predictions reflected the problem of overfitting. \nThis could be due to two circumstances: first, we submitted a multinomial model that had surprisingly high accuracy on our own test set, but this was because the model allowed too much model flexibility, which led to overfitting. Second, we used many predictors without selecting them specifically beforehand, apart from ZeroVariance, multicollinaerity, high correlations . So we also wanted to improve the selection of relevant predictors. In addition, we also added new features that we originally wanted but required more work to implement, and we did not want to overlook potentially good predictors.*","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.2 Initial models for submission round 1\n\nHere we haven' t done forward or backward selection yet, we just tested with these models with our full set of predictors so far.\n\n- LDA (Linear Discriminant Analysis) seemed to us like a good discrimination model for distinguish different activity classes, as it tries to identify linear combinations of characteristics. This could be beneficial, when we find clear linear boundary between different physical activities.\n\n- Multinomial logistic regression seemed like a good model to us, becaus it cannot only distinct two activity classes, but also more, which seemed perfect for our multiple activities as it provides probability estimates for each class. \nIt s based on the idea to detect the likelihood of epochs to belong in one of several possible activity categories based on the sensor data it captures.\n\n- k-NN also could be a suitable option for as as it is an algorithm that puts similar data points in the feature space together. We always used the scaled version of k-NN, because this standardizes the features, which is essential in our case as the features have different scales and k-NN it relies on these as distance metrics. \n\nHere we disable to run them, since it would take to much computational power.\n","metadata":{}},{"cell_type":"code","source":"# LDA\n\n#fit_lda <- caret::train(activity ~ .,\n#                        data = train_df_clean\n#                        method = \"lda\",\n#                        trControl = trcntr\n#                       )\n#fit_lda\n\n# K-Nearest Neighbor (scaled)\n\n#fit_knn <- caret::train(activity ~ ., \n#                        data = train_df_clean\n#                        preProcess = \"scale\", \n#                        method = \"knn\",\n#                        trControl = trcntr)\n#fit_knn\n\n# Multinomial logistic regression\n\n#fit_mlr <- caret::train(activity ~ ., \n#                        data = train_df_clean\n#                        method = \"multinom\", \n#                        trControl = trcntr,\n#                        trace = FALSE  # suppress iterations\n#                        )\n#fit_mlr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.3 Further predictor selection\n\nWe got introduced to different shrinkage methods in Chap. 6 ISLR and one way we wanted to reduce information was by conducting a PCA on the features. Our aim is that a few components can capture the most important information. Inially, we tried the original function pcr() from the \"pls\" package used in the book, but it did not work in a useful way to get easily access to the loadings for interpreting the relationships between the features and the principal components. Therefore we used the prcomp() function, but as we cannot chose our optimal number of principal components by cross-validation now, we have to do a visual inspection with a screeplot. We thought about a component solution with either 15 or 30 principal components based on the elbow criterium, which would account for a good amout of variance. Our initial idea just using these components as predictors didn't work out because using 15 or 30 principal components as predictors lead to very low accuracy in the model predictions. e.g. with 30 components 30 the knn model accuracy dropped to 0.1267312. This was probably due to the mismatching with the activity label in the end. Then we adapted our approach and model to the way sensor group 2 used PCA, by setting a threshold in the PCA to identified the most important features based on the cumulative explained variance of them. This way we could run our different models and our test accuracy was the best with lda, so we tested this one on the leaderboard, turned out our score dropped from the 0.65228 to 0.57254, which wasn' t what we expected. As another appoach we also wanted to try the Lasso. After that we went back to our original model (see 5.2.3) and we wanted to try different machine learning models and to handpick predictors, to see if that made a difference.","metadata":{}},{"cell_type":"code","source":"# Clean Data frame for PCA, excluding all unsuitable variables (logicals, characters)\n# df_clean_pcr <- train_df_clean %>% \n#   select(-c(\"activity\", \"bimodal1_acc\", \"bimodal2_acc\", \"bimodal3_acc\", \"bimodal3_gyr\", \"bimodal3_gyr\", \"bimodal3_gyr\"))  \n# df_clean_pcr <- lapply(df_clean_pcr, function(x) ifelse(x, 1, 0))\n# head(df_clean_pcr)                       \n\n# PCA 1 with pcr() function:\n# install.packages(\"pls\")\n# library (pls)\n# rownames(train_df_clean) <- train_df_clean$activity\n# df_clean_pcr <- train_df_clean[, -1]           \n# pcr.fit <- pcr (activity ~ ., data = df_clean_pcr, scale = TRUE ,validation = \"CV\") \n# we also set standardization so the scale on which each variable is measured will not have an effect\n# summary(pcr.fit) \n# validationplot(pcr.fit , val.type = \"MSEP\")\n\n# PCA 2 with prcomp() function:\n# pca_result <- prcomp(df_clean_pcr, scale = TRUE, center = TRUE) # prcomp can handle raw data\n# summary(pca_result)\n# biplot(pca_result)\n# plot(pca_result, type=\"lines\")\n# another version of plot:\n# eigenvalues <- (pca_result$sdev)^2\n# scree_data <- data.frame( Principal_Component = 1:length(eigenvalues), Eigenvalue = eigenvalues)\n# ggplot(scree_data, aes(x = Principal_Component, y = Eigenvalue)) +\n# geom_point() +  \n# labs(x = \"Principal Component\", y = \"Eigenvalue\") +\n# ggtitle(\"Scree Plot for PCA\")\n# Calculating the first 15 principal components \n# num_components <- 30\n# loadings_matrix <- pca_result$rotation\n# center_vector <- pca_result$center\n# scale_vector <- pca_result$scale\n# pca_components <- scale_vector * loadings_matrix[, 1:num_components]\n# data frame combines these components with the original feature names\n# original_features <- colnames(df_clean_pcr)\n# pca_data <- as.data.frame(pca_components)\n# colnames(pca_data) <- paste0(\"PC\", 1:num_components)\n# rownames(pca_data) <- original_features\n# pca_data_with_labels <- cbind(pca_data, train_df_clean[[\"activity\"]])\n# colnames(pca_data_with_labels)[ncol(pca_data_with_labels)] <- \"activity\"\n\n# fit_lda <- caret::train(activity ~ .,\n#                        data = pca_data_with_labels,  \n#                        method = \"lda\",\n#                        trControl = trcntr\n#                       )\n# fit_lda\n\n# fit_knn <- caret::train(activity ~ ., \n#                        data = pca_data_with_labels, \n#                        preProcess = \"scale\", \n#                        method = \"knn\",\n#                        trControl = trcntr)\n# fit_knn\n\n# fit_mlr <- caret::train(activity ~ ., \n#                        data = pca_data_with_labels, \n#                        method = \"multinom\", \n#                        trControl = trcntr,\n#                        trace = FALSE  # suppress iterations\n#                        )\n# fit_mlr\n\n# PCA 3, adapted approach from sensor group2:\n# library(dplyr)\n# library(purrr)\n# calculate the cumulative explained variance from pca\n# cumulative_variance <- cumsum((pca_result$sdev^2) / sum(pca_result$sdev^2))\n#threshold <- 0.75722\n# select features based on the threshold\n# select_features <- function(threshold) {\n# num_components <- which(cumulative_variance >= threshold)[1]\n# feature_loadings <- loadings_matrix[, 1:num_components]\n# selected_features <- lapply(1:num_components, function(i) {\n# strong_loading_threshold <- ifelse(i == 1, 0.2, 0.25)  # Adjust as needed\n# strong_loadings <- which(abs(feature_loadings[, i]) >= strong_loading_threshold)\n# rownames(feature_loadings)[strong_loadings]})  \n# unique(unlist(selected_features))}\n\n# Get back to our original features\n# selected_features <- select_features(threshold)\n# Lda model\n# predictors <- paste(selected_features, collapse = \" + \")\n# lda_formula <- as.formula(paste(\"activity ~\", predictors))\n# fit_lda <- caret::train(lda_formula, data = train_df_clean, method = \"lda\", trControl = trcntr)\n# fit_lda\n\n# k-NN model\n# predictors <- paste(selected_features, collapse = \" + \")\n# knn_formula <- as.formula(paste(\"activity ~\", predictors))\n# knn_formula <- as.formula(paste(\"activity ~\", predictors))\n# trcntr <- trainControl('cv', number = 5, p = 0.8)\n# fit_knn <- caret::train(knn_formula, data = train_df_clean, method = \"knn\", trControl = trcntr)\n# fit_knn\n\n# multinominal model\n# predictors <- paste(selected_features, collapse = \" + \")\n# mlr_formula <- as.formula(paste(\"activity ~\", predictors))\n# trcntr <- trainControl('cv', number = 5, p = 0.8)\n# fit_mlr <- caret::train(mlr_formula, data = train_df_clean, method = \"multinom\", trControl = trcntr, trace = FALSE)\n# fit_mlr","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.4 Stepwise feature selection\n\nTo try and find the features most relevant to our final model, we perform a forward and backwardmodel selections and compare results of each to try find the best performing models.","metadata":{}},{"cell_type":"code","source":"# Packages required\nsuppressPackageStartupMessages(library(leaps))\n\n# Convert required features to numeric\nconv2num <- c(\n  \"bimodal1_acc\", \"bimodal2_acc\", \"bimodal3_acc\", \"cos_ang2_acc\", \"cos_ang3_acc\",\n  \"bimodal1_gyr\", \"bimodal2_gyr\", \"bimodal3_gyr\", \"cos_ang2_gyr\", \"cos_ang3_gyr\"\n)\ntrain_df_clean_c <- train_df_clean\ntrain_df_clean_c[conv2num] <- lapply(train_df_clean_c[conv2num], as.numeric)\n\n# sapply(train_df_clean_c, class)\n\n# Convert response variable to factor\ntrain_df_clean_c$activity <- as.factor(train_df_clean_c$activity)\nhead(train_df_clean_c)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forward selection of linear model\nfit_fwd <- regsubsets(activity ~ ., train_df_clean_c, nvmax = 53, method = \"forward\")\nsum_fit_fwd <- summary(fit_fwd)\nfit_bwd <- regsubsets(activity ~ ., train_df_clean_c, nvmax = 53, method = \"backward\")\nsum_fit_bwd <- summary(fit_bwd)\n\n## BIC-based best models\nbest_fwd_bic <- which.min(sum_fit_fwd$bic)\nbest_fwd_bic\nfwd_preds_bic <- names(coef(fit_fwd, id = best_fwd_bic))\n# fwd_preds_bic\n\n# Backward selection of linear model\nbest_bwd_bic <- which.min(sum_fit_bwd$bic)\nbest_bwd_bic\nbwd_preds_bic <- names(coef(fit_bwd, id = best_bwd_bic))\n# bwd_preds_bic\n\n# Are both selection methods suggesting the same models? Yes!\nmean(fwd_preds_bic == bwd_preds_bic) == 1\n\n## adjR2-based best models\n# Forward selection of linear model\nbest_fwd_ar2 <- which.max(sum_fit_fwd$adjr2)\nbest_fwd_ar2\nfwd_preds_ar2 <- names(coef(fit_fwd, id = best_fwd_ar2))\n# fwd_preds_ar2\n\n# Backward selection of linear model\nbest_bwd_ar2 <- which.max(sum_fit_bwd$adjr2)\nbest_bwd_ar2\nbwd_preds_ar2 <- names(coef(fit_bwd, id = best_bwd_ar2))\n# bwd_preds_ar2\n\n# plot\n\nplots_metrics <- function(x, metric, name) {\n  plot <- data.frame(\n    met = x,\n    n_pred = 1:length(x)\n  ) %>%\n    rename(metric = met) %>%\n    ggplot(aes(x = n_pred, y = metric)) +\n    geom_point() +\n    geom_line() +\n    theme_classic() +\n    theme(aspect.ratio = 1) +\n    labs(title = name, x = \"Number of Predictors\", y = metric)\n  return(plot)\n}\n\ngridExtra::grid.arrange(\n  plots_metrics(\n    x = sum_fit_fwd$bic,\n    metric = \"BIC\",\n    name = \"Forward Stepwise Selection\"\n  ),\n  plots_metrics(\n    x = sum_fit_fwd$adjr2,\n    metric = \"Adjusted R²\",\n    name = \"Forward Stepwise Selection\"\n  ),\n  ncol = 2\n)\ngridExtra::grid.arrange(\n  plots_metrics(\n    x = sum_fit_bwd$bic,\n    metric = \"BIC\",\n    name = \"Backward Stepwise Selection\"\n  ),\n  plots_metrics(\n    x = sum_fit_bwd$adjr2,\n    metric = \"Adjusted R²\",\n    name = \"Backward Stepwise Selection\"\n  ),\n  ncol = 2\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** From the forward and backward methods selection we can see that BIC recommends choosing models that have 33 predictors included, whereas adjusted R2 would recommend using models with 49 or 50 predictors. During this competition, we have tried out several models resulting in minimum 40 predictors, which have all yielded test prediction accuracies of 0.6-0.67. Furthermore, both forward and backward selection methods suggested the same predictors be included. As we suspect we are overfitting, we will go with the 33 predictors recommended by BIC. \n\nIn the next section, we use these predictors to fit and compare different classifications models in attempt to increase prediction accuracy again.","metadata":{}},{"cell_type":"markdown","source":"#### 5.2.4.1 LDA Model","metadata":{}},{"cell_type":"code","source":"# Take out first column name \"Intercept\" from fwd_preds_bic\nfwd_preds_bic <- fwd_preds_bic[-1]\n#fwd_preds_bic\n\n# LDA model with forward BIC predictors\nfit_lda_bic <- caret::train(activity ~ .,\n                        data = train_df_clean[, c(\"activity\", fwd_preds_bic)],\n                        method = \"lda\",\n                        trControl = trcntr\n                       )\nfit_lda_bic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.4.2 kNN Model","metadata":{}},{"cell_type":"code","source":"# kNN model with forward BIC predictors\nfit_knn_bic <- caret::train(activity ~ ., \n                        data = train_df_clean[, c(\"activity\", fwd_preds_bic)],\n                        preProcess = \"scale\", \n                        method = \"knn\",\n                        trControl = trcntr)\nfit_knn_bic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2.4.3 Multinomial regression model","metadata":{}},{"cell_type":"code","source":"fit_mlr_bic <- caret::train(activity ~ ., \n                        data = train_df_clean[, c(\"activity\", fwd_preds_bic)],\n                        method = \"multinom\", \n                        trControl = trcntr,\n                        trace = FALSE  # suppress iterations\n                        )\nfit_mlr_bic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Model comparison\nThe **knn scaled model returns the highest accuracy** on the training data using a 5-fold cross validation technique. Accordingly, we will use this model for the prediction of the test data activity labels.    \n\nIn order to compare the different models, we used the adjusted R squared on the one hand for assessing the goodness of model fit, as it also punishes for the amount of predictors in the model, and the BIC for selecting the most parsimonious model, which has a good balances between goodness of fit and model complexity. ","metadata":{}},{"cell_type":"markdown","source":"## 5.3.1 Visual model comparison","metadata":{}},{"cell_type":"code","source":"# gather the different models in a list\nlist_models <- list(\n  LDA = fit_lda_bic,\n  KNN = fit_knn_bic,\n  MLR = fit_mlr_bic\n)\n\n# extract and list the accuracy values\naccuracy <- sapply(\n  list_models,\n  function(mod) {\n    return(max(mod$results$Accuracy))\n  }\n)\n\n# Set up data frame for model comparison plot:\ntbl_acc <-\n  accuracy %>%\n  bind_rows() %>%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"model\",\n    values_to = \"accuracy\"\n  ) %>%\n  mutate(\n    classifier = str_extract(model, \"LDA|KNN|KNNS|MLR\"),\n    mod_choice = case_when(accuracy == max(accuracy) ~ \"choice\")\n  )\n\n# plot\ntbl_acc %>%\n  ggplot(aes(x = model, y = accuracy, fill = mod_choice)) +\n  geom_bar(\n    stat = \"identity\",\n    linewidth = 5,\n    width = .8\n  ) +\n  geom_text(aes(label = str_replace(round(accuracy, 3), \"0.\", \".\")),\n    nudge_y = -.04\n  ) +\n  scale_y_continuous(\n    name = \"Training Data Prediction Accuracy\",\n    limits = c(0, 1)\n  ) +\n  scale_fill_discrete(guide = \"none\") +\n  theme_classic() +\n  theme(axis.title.y = element_text(margin = margin(r = 10))) +\n  labs(\n    title = \"Comparison of Training Data Prediction Accuracy\",\n    x = \"Model\"\n  )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3.3 Decision on final model\n\n<span style = 'color:red;'> knn_bic </span>","metadata":{}},{"cell_type":"markdown","source":"<h1 id = prediction_test style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    6. Prediction on test data\n</h1>\nIn this section, we first import the test data and extract the features using our custom function.   \nNext, we apply our model in order to predict the activity label of each epoch in our test data.\n\n## 6.1 Import test data\nTo import the test data and extract the features, we can easily use our `extract_features` function","metadata":{}},{"cell_type":"code","source":"# Accelerometer data\nfilenames_test <- list.files(\"./RawData/Test/\", \"^acc\", full.names = TRUE)\ntest_data_acc <- map_dfr(filenames_test, extract_features, sample_labels)\n\n# Gyroscope data\nfilenames_test <- list.files(\"./RawData/Test/\", \"^gyr\", full.names = TRUE)\ntest_data_gyr <- map_dfr(filenames_test, extract_features, sample_labels)\n\n# Merge\ntest_data <- test_data_acc %>%\n  left_join(test_data_gyr,\n    by = c(\"epoch\", \"user_id\", \"exp_id\", \"activity\", \"sampleid\", \"n_samples\"),\n    suffix = c(\"_acc\", \"_gyr\")\n  ) %>%\n  select(-c(\"epoch\", \"activity\", \"n_samples\"))\n\nhead(test_data)\ndim(test_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Prediction on test data\nNow we can use our model to predict the activities in the test data.\nHowever, as noted earlier, there are two epochs in the test data that show an insufficient count of samples. These two epoch will obtain a missing activity labels since the data for these two epochs is not complete enough for a prediction using our model. ","metadata":{}},{"cell_type":"code","source":"pred_test <- predict(fit_knn_bic, test_data)\n\npred_test <- tibble(user_id = test_data$user_id,\n                    exp_id = test_data$exp_id,\n                    sampleid = test_data$sampleid,\n                    activity = pred_test)\n\nhead(pred_test)\ndim(pred_test)\n\n# Two warnings can be expected: They concern the lagged correlation coefficients\n# for the two epochs that contain only a few samples.\n# These correlations have been set to 0 (compare reasoning above).","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id = submission style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    7. Formatting the submission file\n</h1>\n\nThe following code was given in order to help obtain the correct format of the submission file.","metadata":{"_uuid":"9d6811f2aa519b89fdd455e046c1201e82109a67","trusted":true}},{"cell_type":"code","source":"pred_test %>%\n  # prepend \"user\" and \"exp\" to user_id and exp_id\n  mutate(\n    user_id = paste(ifelse(user_id < 10, \"user0\", \"user\"), user_id, sep = \"\"),\n    exp_id = paste(ifelse(exp_id < 10, \"exp0\", \"exp\"), exp_id, sep = \"\")\n  ) %>%\n  # unit columnes user_id, exp_id and sample_id into a string\n  # separated by \"_\" and store it in the new variable `Id`\n  unite(Id, user_id, exp_id, sampleid) %>%\n  # retain only the `Id` and  predictions\n  select(Id, Predicted = activity) %>%\n  # write to file\n  write_csv(\"submission.csv\")\n\n\n# Check the result: print first 20 lines in the submission file\ncat(readLines(\"submission.csv\", 20), sep = \"\\n\")","metadata":{"_uuid":"d7eb43a15f0e63a6a6e1c2474bda14e82094abb2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id = refs_decl style = 'font-size:26px; background: #581C3D; color: #F3F3F3; padding: 10px; border-radius: 10px;'>\n    8. References & Declaration of work\n</h1>\n\n\n## References\nCarús JL, Peláez V, López G, Lobato V. JIM: a novel and efficient accelerometric magnitude to measure physical activity. Stud Health Technol Inform. 2012;177:283-8. PMID: 22942068\n\n[Grasman, R. (2018). Feature extraction from signals.](https://paper.dropbox.com/doc/Feature-extraction-from-Signals-qCp5uvj47gmyuw5nmB8lL) \n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An Introduction to Statistical Learning: with Applications in R. (https://link.springer.com/content/pdf/10.1007/978-1-0716-1418-1.pdf)\n\nTheodoros Giannakopoulos, Aggelos Pikrakis, Introduction to Audio Analysis, 2014, (https://doi.org/10.1016/B978-0-08-099388-1.00009-1)\n\nZhu, J., San-Segundo, R. & Pardo, J.M. (2017). Feature extraction for robust physical activity recognition. Hum. Cent. Comput. Inf. Sci. 7, 16. (https://doi.org/10.1186/s13673-017-0097-2)\n\n\n## Declaration of work\nAll three members of the team contributed equally to this project.","metadata":{}}]}